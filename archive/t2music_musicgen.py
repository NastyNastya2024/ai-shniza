import os
import asyncio
import logging
from dotenv import load_dotenv
import aiohttp

from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.types import FSInputFile, Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN")

logging.basicConfig(level=logging.INFO)

bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML)
)
dp = Dispatcher()

REPLICATE_MODEL_VERSION = "671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb"
REPLICATE_API_URL = "https://api.replicate.com/v1/predictions"

HEADERS = {
    "Authorization": f"Token {REPLICATE_API_TOKEN}",
    "Content-Type": "application/json"
}

MODEL_VERSIONS = {
    "stereo-large": "Stereo Large",
    "stereo-melody-large": "Stereo Melody Large",
    "melody-large": "Melody Large",
    "large": "Large"
}

NORMALIZATION_STRATEGIES = {
    "loudness": "Loudness",
    "clip": "Clip",
    "peak": "Peak",
    "rms": "RMS"
}

class MusicGenStates(StatesGroup):
    choosing_model = State()
    choosing_normalization = State()
    waiting_for_prompt = State()

@dp.message(Command("start"))
async def start_handler(message: Message, state: FSMContext):
    """
    –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –±–æ—Ç–∞ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏.
    """
    await state.clear()
    welcome_text = (
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø MusicGen ‚Äî –±–æ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–∑—ã–∫–∏ –ø–æ —Ç–≤–æ–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–º –æ–ø–∏—Å–∞–Ω–∏—è–º.\n\n"
        "üí° –ß—Ç–æ –º–æ–∂–µ—Ç MusicGen:\n"
        "- –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º—É–∑—ã–∫—É –ø–æ —Ç–≤–æ–µ–º—É –ø—Ä–æ–º–ø—Ç—É (–æ–ø–∏—Å–∞–Ω–∏—é)\n"
        "- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏: –æ—Ç —Å—Ç–µ—Ä–µ–æ –¥–æ –º–µ–ª–æ–¥–∏–π\n"
        "- –ü–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–±—Ä–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–≤—É–∫–∞\n\n"
        "‚ö†Ô∏è –í–ê–ñ–ù–û: –ø—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.\n\n"
        "‚è≥ –û–¥–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –æ–∫–æ–ª–æ 20-30 —Å–µ–∫—É–Ω–¥.\n"
        "üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –æ–¥–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ‚Äî –æ–∫–æ–ª–æ $1.\n\n"
    )

    model_keyboard = InlineKeyboardMarkup(
        inline_keyboard=[
            [InlineKeyboardButton(text=name, callback_data=key)] for key, name in MODEL_VERSIONS.items()
        ]
    )
    await message.answer(welcome_text, reply_markup=model_keyboard)
    await state.set_state(MusicGenStates.choosing_model)

@dp.callback_query(MusicGenStates.choosing_model)
async def model_chosen(query: CallbackQuery, state: FSMContext):
    selected_model = query.data
    if selected_model not in MODEL_VERSIONS:
        await query.answer("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏, –ø–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.", show_alert=True)
        return

    await state.update_data(model_version=selected_model)
    await query.answer(f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {MODEL_VERSIONS[selected_model]}")

    norm_keyboard = InlineKeyboardMarkup(
        inline_keyboard=[
            [InlineKeyboardButton(text=name, callback_data=key)] for key, name in NORMALIZATION_STRATEGIES.items()
        ]
    )
    await query.message.answer(
        "üéö –¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–≤—É–∫–∞:\n"
        "- loudness: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏\n"
        "- clip: –æ–±—Ä–µ–∑–∞–Ω–∏–µ –ø–∏–∫–æ–≤\n"
        "- peak: –ø–∏–∫–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n"
        "- rms: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Å—Ä–µ–¥–Ω–µ–π –º–æ—â–Ω–æ—Å—Ç–∏\n\n"
        "–í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:",
        reply_markup=norm_keyboard
    )
    await state.set_state(MusicGenStates.choosing_normalization)

@dp.callback_query(MusicGenStates.choosing_normalization)
async def normalization_chosen(query: CallbackQuery, state: FSMContext):
    selected_norm = query.data
    if selected_norm not in NORMALIZATION_STRATEGIES:
        await query.answer("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, –ø–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.", show_alert=True)
        return

    await state.update_data(normalization_strategy=selected_norm)
    await query.answer(f"–í—ã–±—Ä–∞–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: {NORMALIZATION_STRATEGIES[selected_norm]}")

    await query.message.answer(
        "‚úçÔ∏è –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n"
        "–ü—Ä–∏–º–µ—Ä (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º): \"A calm piano melody with ambient background\""
    )
    await state.set_state(MusicGenStates.waiting_for_prompt)

@dp.message(MusicGenStates.waiting_for_prompt)
async def receive_prompt(message: Message, state: FSMContext):
    prompt = message.text.strip()
    if len(prompt) < 5:
        await message.answer("‚ùå –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    data = await state.get_data()
    model_version = data.get("model_version", "stereo-large")
    normalization_strategy = data.get("normalization_strategy", "peak")

    await message.answer("üé∂ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏... –ü–æ–¥–æ–∂–¥–∏ 20-30 —Å–µ–∫—É–Ω–¥...")

    async with aiohttp.ClientSession() as session:
        prediction_payload = {
            "version": REPLICATE_MODEL_VERSION,
            "input": {
                "prompt": prompt,
                "duration": 8,
                "output_format": "mp3",
                "model_version": model_version,
                "classifier_free_guidance": 3,
                "temperature": 1,
                "top_k": 250,
                "top_p": 0,
                "continuation": False,
                "multi_band_diffusion": False,
                "normalization_strategy": normalization_strategy
            }
        }

        async with session.post(REPLICATE_API_URL, json=prediction_payload, headers=HEADERS) as response:
            prediction = await response.json()
            prediction_id = prediction.get("id")
            if not prediction_id:
                await message.answer("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {prediction}")
                return

        output_url = None
        for _ in range(40):
            async with session.get(f"{REPLICATE_API_URL}/{prediction_id}", headers=HEADERS) as poll_response:
                result = await poll_response.json()
                status = result.get("status")
                if status == "succeeded":
                    output_url = result.get("output")
                    break
                elif status == "failed":
                    await message.answer("‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
                    return
            await asyncio.sleep(1)

        if not output_url:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∞—É–¥–∏–æ.")
            return

        filename = "generated_track.mp3"
        async with session.get(output_url) as music_response:
            if music_response.status == 200:
                with open(filename, "wb") as f:
                    f.write(await music_response.read())
            else:
                await message.answer("‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∞—É–¥–∏–æ.")
                return

        await message.answer_audio(FSInputFile(filename), caption="üéß –í–æ—Ç —Ç–≤–æ—è –º—É–∑—ã–∫–∞!")
        os.remove(filename)

    await state.clear()

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
